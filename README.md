# ğŸ’¸ Pipeline de Controle de Gastos Automatizado

# Em desenvolvimento

Este projeto tem como objetivo automatizar o controle de gastos pessoais, substituindo o processo manual anteriormente utilizado. O pipeline Ã© composto pelas etapas clÃ¡ssicas de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga), alÃ©m de visualizaÃ§Ã£o e orquestraÃ§Ã£o automatizada.

---

## ğŸ“¦ Tecnologias Utilizadas

- ğŸ“§ [imap-tools](https://github.com/ikvk/imap_tools) â€“ ExtraÃ§Ã£o de anexos de faturas e contas via e-mail.
- âš™ï¸ Apache Spark â€“ Processamento e transformaÃ§Ã£o dos dados.
- ğŸ“Š Microsoft Excel / Power BI â€“ VisualizaÃ§Ã£o e anÃ¡lise dos dados.
- â± Apache Airflow â€“ OrquestraÃ§Ã£o e automaÃ§Ã£o do pipeline.

---

## ğŸ”„ Etapas do Pipeline

### 1. ExtraÃ§Ã£o (Extract)
- Acessa automaticamente a conta de e-mail.
- Extrai os anexos de faturas e outras contas recebidas.
- Utiliza a biblioteca `imap_tools` para lidar com o protocolo IMAP.

### 2. TransformaÃ§Ã£o (Transform)
- Os arquivos extraÃ­dos sÃ£o processados com **Apache Spark**.
- Os dados sÃ£o limpos, padronizados e enriquecidos.
- Essa etapa Ã© utilizada para estudo prÃ¡tico dos conceitos do Spark.


### 3. Carga (Load)
- Os dados tratados sÃ£o carregados para arquivos locais ou banco de dados.
- Essa etapa tambÃ©m Ã© feita com Apache Spark, integrando as transformaÃ§Ãµes.

### 4. VisualizaÃ§Ã£o 
- UtilizaÃ§Ã£o do **Excel** e **Power BI** para anÃ¡lise dos gastos.
- CriaÃ§Ã£o de dashboards e grÃ¡ficos para acompanhar os gastos mensais.

### 5. AutomaÃ§Ã£o (SerÃ¡ desenvolvida)
- O **Apache Airflow** serÃ¡ utilizado para agendar e automatizar todo o fluxo do pipeline.
- Garante que a extraÃ§Ã£o, transformaÃ§Ã£o, carga e visualizaÃ§Ãµes sejam atualizadas automaticamente.

---

## ğŸ§ª PrÃ³ximos Passos

- âœ… Adicionar testes unitÃ¡rios nas etapas de extraÃ§Ã£o e transformaÃ§Ã£o.
- âœ… Automatizar execuÃ§Ã£o diÃ¡ria/semanal com Apache Airflow.
- âœ… Colocar o projeto em produÃ§Ã£o em um servidor local.

---

## ğŸ§  Objetivo Educacional
Este projeto tambÃ©m tem fins educacionais, sendo utilizado para praticar:

- Processamento de dados com Apache Spark.

- AutomatizaÃ§Ã£o de workflows com Apache Airflow.

- CriaÃ§Ã£o de relatÃ³rios dinÃ¢micos com ferramentas de BI.

- Boas prÃ¡ticas com testes e organizaÃ§Ã£o de pipelines de dados.

---

## ğŸ“ Estrutura do Projeto

```plaintext
pipeline_faturas/
â”œâ”€â”€ models/             # Entidades
â”œâ”€â”€ notebooks/          # Notebooks Jupyter
â”œâ”€â”€ scripts/            # Scripts de extraÃ§Ã£o,transformaÃ§Ã£o de dados e carregamento
â”‚   â””â”€â”€ extracts/
â”œâ”€â”€ main.py             # Script principal para execuÃ§Ã£o do pipeline
â”œâ”€â”€ .gitignore          # Arquivos e pastas ignorados pelo Git
â””â”€â”€ README.md           # DocumentaÃ§Ã£o do projeto



